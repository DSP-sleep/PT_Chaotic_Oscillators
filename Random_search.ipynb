{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for random parameter search.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from numba import jit\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from scipy.integrate import odeint\n",
    "from scipy.signal import periodogram\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "error_message = 'Excess work done on this call (perhaps wrong Dfun type).'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def DvD(S, t, k, K):\n",
    "    \"\"\"\n",
    "    The function of the system for scipy.integrate.odeint.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    S : array\n",
    "    Condition of substrates \n",
    "    t : array\n",
    "    A sequence of time points.\n",
    "    k : array\n",
    "    Rate constants.\n",
    "    K: array\n",
    "    MM constants.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Sintg : array\n",
    "    The change of S.\n",
    "    \"\"\"\n",
    "    \n",
    "    Sintg = np.empty(6)\n",
    "    Sa_00, Sa_01, Sa_10, Sb_00, Sb_01, Sb_10 = S\n",
    "    \n",
    "    E = 20./(1 + Sa_00/K[0] + Sa_00/K[1] + Sa_01/K[2]   + Sa_10/K[3]\n",
    "                  + Sb_00/K[8] + Sb_00/K[9] + Sb_01/K[10] + Sb_10/K[11])\n",
    "    F = 20./(1 + Sa_01/K[4]   + Sa_10/K[5]   + (1000.-Sa_00-Sa_01-Sa_10)/K[6]   + (1000.-Sa_00-Sa_01-Sa_10)/K[7]\n",
    "                  + Sb_01/K[12] + Sb_10/K[13] + (1000.-Sb_00-Sb_01-Sb_10)/K[14] + (1000.-Sb_00-Sb_01-Sb_10)/K[15])\n",
    "             \n",
    "    Sintg[0] = - k[0]*E*Sa_00/K[0] - k[1]*E*Sa_00/K[1] + k[4]*F*Sa_01/K[4] + k[5]*F*Sa_10/K[5]\n",
    "    Sintg[1] = - k[4]*F*Sa_01/K[4] - k[2]*E*Sa_01/K[2] + k[0]*E*Sa_00/K[0] + k[6]*F*(1000.-Sa_00-Sa_01-Sa_10)/K[6]\n",
    "    Sintg[2] = - k[5]*F*Sa_10/K[5] - k[3]*E*Sa_10/K[3] + k[1]*E*Sa_00/K[1] + k[7]*F*(1000.-Sa_00-Sa_01-Sa_10)/K[7]\n",
    "    Sintg[3] = - k[8]*E*Sb_00/K[8] - k[9]*E*Sb_00/K[9] + k[12]*F*Sb_01/K[12] + k[13]*F*Sb_10/K[13]\n",
    "    Sintg[4] = - k[12]*F*Sb_01/K[12] - k[10]*E*Sb_01/K[10] + k[8]*E*Sb_00/K[8] + k[14]*F*(1000.-Sb_00-Sb_01-Sb_10)/K[14]\n",
    "    Sintg[5] = - k[13]*F*Sb_10/K[13] - k[11]*E*Sb_10/K[11] + k[9]*E*Sb_00/K[9] + k[15]*F*(1000.-Sb_00-Sb_01-Sb_10)/K[15]\n",
    "             \n",
    "    return(Sintg)\n",
    "\n",
    "@jit\n",
    "def check_convergence(v, trange, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Judge if each state of a substrate is convergent.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    v : array\n",
    "    A sequence of a state of a substrate.\n",
    "    trange : int\n",
    "    The time the integration was done.\n",
    "    epsilon : scalar\n",
    "    A threshold for the judge.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    1 if not convergence.\n",
    "    \"\"\"\n",
    "    \n",
    "    rang = trange//10\n",
    "    \n",
    "    # check convergence\n",
    "    vstd = np.std(v[-rang:])\n",
    "    \n",
    "    diffstd = np.std(np.diff(v[-rang:]))\n",
    "    if diffstd < epsilon:\n",
    "        return(3)\n",
    "    elif vstd < epsilon:\n",
    "        return(0)\n",
    "    else:\n",
    "        return(1) # not convergence\n",
    "    \n",
    "def gen_kK():\n",
    "    \"\"\"\n",
    "    Randomly generate 32 parameters that determine the system.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    k : array\n",
    "    Rate constants.\n",
    "    K : array\n",
    "    MM constants.\n",
    "    \"\"\"\n",
    "    \n",
    "    rk = np.random.rand(16)\n",
    "    rK = np.random.rand(16)\n",
    "    \n",
    "    k = 10**(3*rk)\n",
    "    K = 10**(5*rK-2)\n",
    "    \n",
    "    return(k, K)\n",
    "\n",
    "def random_search(args):\n",
    "    \"\"\"\n",
    "    Iterate random parameter generation and classification of chaotic solutions.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    args : tuple, shape (2)\n",
    "        i_core : int\n",
    "            Specify which cpu core is used.\n",
    "        n_iter : int\n",
    "            How much iteration is done by each cpu core.\n",
    "    \"\"\"\n",
    "    \n",
    "    i_core, n_iter = args\n",
    "    \n",
    "    S0 = np.asarray([1000., 0., 0., 1000., 0., 0.]) # initial state of the substrates.\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date = '{}_{}_{}_{}_{}_{}_{}'.format(now.year, now.month, now.day, now.hour, now.minute, now.second, i_core)\n",
    "    np.random.seed(int('{}_{}_{}_{}_'.format(i_core, now.day, now.hour, now.minute)+str(now.microsecond)[-4:-2]))\n",
    "    \n",
    "    # the path to save the search results.\n",
    "    filename = './random_{:02}.pickle'.format(i_core)\n",
    "    #filename_osci = './random_{:02}_osci.pickle'.format(i_core)\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            ongoing = pickle.load(f)\n",
    "            i_iter = ongoing[0]\n",
    "            n_osci = ongoing[1]\n",
    "            chaos_maybe = ongoing[2:]\n",
    "        #with open(filename_osci, 'rb') as f:\n",
    "        #    osci_maybe = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        i_iter = np.zeros(1)\n",
    "        n_osci = np.zeros(1)\n",
    "        chaos_maybe = []\n",
    "        #osci_maybe = []\n",
    "\n",
    "    judge = np.zeros(6, dtype='int')\n",
    "\n",
    "    st = time()\n",
    "    for iteration in tqdm(range(int(n_iter))):\n",
    "        i_iter += 1\n",
    "        k, K = gen_kK()\n",
    "        \n",
    "        trange = 1000\n",
    "        \n",
    "        # quick integration\n",
    "        S, info = odeint(func=DvD, y0=S0, t=np.arange(0, trange, 0.02), args=(k, K), atol=5.0e-4, rtol=5.0e-4, full_output=1)\n",
    "        if error_message==info['message']:\n",
    "            pass\n",
    "        else:\n",
    "            for col in range(6):\n",
    "                judge[col] = check_convergence(v=S[:, col], trange=trange*50)\n",
    "            if 1 in judge:\n",
    "                # integration again\n",
    "                S, info = odeint(func=DvD, y0=S0, t=np.arange(0, trange, 0.02), args=(k, K), full_output=1)\n",
    "                if error_message==info['message']:\n",
    "                    pass\n",
    "                else:\n",
    "                    for col in range(6):\n",
    "                        judge[col] = check_convergence(v=S[:, col], trange=trange*50)\n",
    "                    if 1 in judge:\n",
    "                        trange = 6000\n",
    "                        # careful integration\n",
    "                        S, info = odeint(func=DvD, y0=S[-1, :], t=np.arange(0, trange, 0.02), args=(k,K), mxstep=10000, atol=1.0e-5, rtol=1.0e-5, full_output=1)\n",
    "                        if error_message == info['message']:\n",
    "                            pass\n",
    "                        else:\n",
    "                            for col in range(6):\n",
    "                                judge[col] = check_convergence(v=S[:, col], trange=trange*50)\n",
    "                                \n",
    "                            # if not convergent, judge if oscillatory or chaotic. \n",
    "                            if 1 in judge:\n",
    "                                f, Spw = periodogram(S[np.int(trange*50/2):], fs=50, axis=0)\n",
    "                                maxfq_row = np.argmax(Spw)//Spw.shape[1]\n",
    "                                maxfq_col = np.argmax(Spw)%Spw.shape[1]\n",
    "                                maxfq_rate = np.sum(Spw[maxfq_row-2:maxfq_row+3, maxfq_col])/np.sum(Spw[:, maxfq_col])\n",
    "                                if 0.15 > maxfq_rate:\n",
    "                                    print('hit!')\n",
    "                                    chaos_maybe.append([k, K]) # seems to be chaos \n",
    "                                else:\n",
    "                                    n_osci += 1\n",
    "                                    #osci_maybe.append([k, K]) # oscillation\n",
    "\n",
    "        # save the intermediate result every hour.\n",
    "        if (time()-st)>60*60:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump([i_iter, n_osci] + chaos_maybe, f)\n",
    "\n",
    "            with open(filename_osci, 'wb') as f:\n",
    "                pickle.dump(osci_maybe, f)\n",
    "\n",
    "            st = time()\n",
    "\n",
    "    print(filename)\n",
    "    #with open(filename, 'wb') as f:\n",
    "    #    pickle.dump([niter, nosci] + chaos_maybe, f)\n",
    "    #with open(filename_osci, 'wb') as f:\n",
    "    #    pickle.dump(osci_maybe, f)\n",
    "\n",
    "    print(datetime.now(), 'Core{}: {} chaos_maybe pickled'.format(i_core, len(chaos_maybe)))\n",
    "    #print(datetime.now(), 'Core{}: {} osci_maybe pickled'.format(i_core, len(osci_maybe)))\n",
    "    \n",
    "def multi_random_search(n_cores, n_iter_per_core=100000000):\n",
    "    \"\"\"\n",
    "    A function to do random search using multiple cpu cores.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    n_cores : int\n",
    "    How many cpu cores to use.\n",
    "    n_iter_per_core : int\n",
    "    How many iterations each core continues.\n",
    "    \"\"\"\n",
    "    \n",
    "    args = []\n",
    "    for i_core in range(n_cores):\n",
    "        args.append((i_core, n_iter_per_core))\n",
    "    \n",
    "    #print('Random search: using ' + str(cores) +' cores to explore chaos.')\n",
    "    print('Random search: using {} cores to explore chaos.'.format(n_cores))\n",
    "    with Pool(processes=n_cores) as pool:\n",
    "        result = pool.map(random_search, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_random_search(10, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
